{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df1 = pd.read_csv('item_properties_part1.csv')\n",
    "df2 = pd.read_csv('item_properties_part2.csv')\n",
    "\n",
    "properties_df = pd.concat([df1, df2])\n",
    "events_df = pd.read_csv('events.csv')\n",
    "category_df = pd.read_csv('category_tree.csv')\n",
    "\n",
    "# change timestamp to more useful format\n",
    "properties_df.timestamp = pd.to_datetime(properties_df['timestamp'], unit='ms')\n",
    "events_df.timestamp = pd.to_datetime(events_df['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first look at data\n",
    "display(properties_df.head())\n",
    "display(events_df.head())\n",
    "display(category_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have plenty of rows in properties and only \"property\" values of \"categoryid\" and \"available\" are not hashed\n",
    "# Thus we decide to remove all rows except where \"availalbe\" is 1 or we have the \"categoryid\"\n",
    "# df_filtered = df[df['Age'] >= 25]\n",
    "properties_df = properties_df[(properties_df.property == \"categoryid\") | ((properties_df.property == \"available\") & (properties_df.value == '1'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df.property.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "# check for missing values and look at histograms and counts\n",
    "\n",
    "# how many na values in category parent and child columns - there are 25 categories with no parent\n",
    "print('na category values', category_df.isnull().sum(axis = 0))\n",
    "\n",
    "# number of rows in category df\n",
    "print('number of rows in category df', category_df.shape[0])\n",
    "\n",
    "# how many unique parent category ids\n",
    "print('unique parent', category_df['parentid'].unique().size)\n",
    "\n",
    "# how many unique child category ids\n",
    "print('unique child', category_df['categoryid'].unique().size)\n",
    "\n",
    "# how many children ids to the top parent categories have\n",
    "n = 20\n",
    "counts = pd.value_counts(category_df['parentid'].values)\n",
    "print(\"child counts for top {} parent IDs\".format(n), sorted(counts, reverse=True)[:n])\n",
    "\n",
    "# clearly events are dominated by views and there are no missing values in the events column\n",
    "counts = pd.value_counts(events_df['event'].values)\n",
    "print(counts)\n",
    "counts.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are only 25 rows with nan values in category_df we decide to eliminate them\n",
    "category_df = category_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have too many items at the moment - causing too many columns in our ranking matrix\n",
    "# we determine to remove items that have been viewed fewer than 30 times by all visitors and that have not been added to a cart or purchased\n",
    "'''\n",
    "This function takes in the events data frame and minimum thresholds for the \"event\"'s, \"view\", \"addtocart\", \n",
    "and \"transaction\" and returns a data frame that only includes \"itemid\"'s, products, that have been viewed, added, or purchased\n",
    "enough times to meet one of the minimum threholds. Basically, we are only looking at items that meet a minimum activity requiremnt.\n",
    "Since we have to cut some items for both memory and compuational efficiency it made the most sense keep \"hot\" itmes for which rankings\n",
    "would be the most valuable.\n",
    "'''\n",
    "def get_reduced_events(e_df=events_df, view_threshold =  200, add_to_cart_threshold = 40, transaction_threshold = 20):\n",
    "    view_counts = pd.value_counts(events_df[events_df.event == 'view']['itemid'].values)\n",
    "    add_to_cart_counts = pd.value_counts(events_df[events_df.event == 'addtocart']['itemid'].values)\n",
    "    transaction_counts = pd.value_counts(events_df[events_df.event == 'transaction']['itemid'].values)\n",
    "    keep_view = view_counts[view_counts.values >= view_threshold]\n",
    "    keep_add_to_cart = add_to_cart_counts[add_to_cart_counts.values >= add_to_cart_threshold]\n",
    "    keep_transaction = transaction_counts[transaction_counts.values >= transaction_threshold]\n",
    "    events_reduced_df = events_df[(events_df.itemid.isin(keep_view.index)) | (events_df.itemid.isin(keep_add_to_cart.index)) | (events_df.itemid.isin(keep_transaction.index))]\n",
    "    return events_reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This fuction takes in the events, properties, and category data frames.\n",
    "It also takes two boolean parameters for addtocart and transaction events\n",
    "when these values are true it keeps track of itemids that are either added to cart or purchased in each row\n",
    "example: if both parameters are set to True and in row 1 items 1105 and 1207 were added to cart and or purchased \n",
    "the target value, y_array, whould have the set {1105, 1207} stored as the ground truth for row 1.\n",
    "Additionally it takes weights for the three event types for a given item, its siblings (items with a common categoryid),\n",
    "and its cousins (itmes with a common parentid (some categoryids have parentids)).\n",
    "Finally it has two additional boolean parameters, realtive and distant relative, that turn the checks for siblings and cousins\n",
    "on and off.\n",
    "It returns the rank matrix, y_vals and itemids\n",
    "'''\n",
    "def get_rank_matrix(e_df=events_df, p_df=properties_df, c_df=category_df, \n",
    "                    y_event_add_to_cart=True, y_event_transaction=True,\n",
    "                    item_view=3, item_add=10, item_purchase=10, \n",
    "                    relative_view=2, relative_add=5, relative_purchase=5, relative=False, \n",
    "                    distant_relative_view=1, distant_relative_add=2, distant_relative_purchase=2, distant_relative=False,\n",
    "                   ):\n",
    "    \n",
    "    products = np.intersect1d(e_df.itemid.unique(), p_df.itemid.unique(), assume_unique=True)\n",
    "    e_df = e_df[e_df.itemid.isin(products)]\n",
    "    p_df = p_df[p_df.itemid.isin(products)]\n",
    "    \n",
    "    visitors = e_df.visitorid.unique()\n",
    "    \n",
    "    rank_matrix = np.zeros((visitors.size, products.size))\n",
    "    \n",
    "    item_idx_dict = dict(zip(products,range(products.size)))\n",
    "\n",
    "    y_vals = [set() for x in range(visitors.size)]\n",
    "    y_events = np.array(['addtocart', 'transaction'])\n",
    "    y_events = y_events[[y_event_add_to_cart, y_event_transaction]]\n",
    "    \n",
    "    print('rank_matrix_size is', rank_matrix.shape)\n",
    "\n",
    "    events_dict = defaultdict(lambda: defaultdict(lambda: []))\n",
    "    for event, visitorid, itemid in e_df[['event', 'visitorid', 'itemid']].values:\n",
    "        events_dict[event][visitorid].append(itemid)\n",
    "    \n",
    "    if relative or distant_relative:\n",
    "        common_df = p_df[(p_df.property == 'categoryid')]\n",
    "        common_df.value = common_df.value.astype(int)\n",
    "        \n",
    "        relatives_dict = defaultdict(lambda: set())\n",
    "        for value, itemid in common_df[['value', 'itemid']].values:\n",
    "            relatives_dict[value].add(itemid)\n",
    "            \n",
    "        common_dict = common_df.set_index('itemid').to_dict()['value']\n",
    "        \n",
    "        siblings_dict = {}\n",
    "        for itemid, categoryid in common_dict.items():\n",
    "            if categoryid in relatives_dict:\n",
    "                siblings_dict[itemid] = relatives_dict[categoryid] - set([itemid])\n",
    "                \n",
    "        if distant_relative:\n",
    "            category_ids = common_df.value.unique()\n",
    "            c_df = c_df[c_df.categoryid.isin(category_ids)]\n",
    "\n",
    "            parent_dict = defaultdict(lambda: set())\n",
    "            for parentid, categoryid in c_df[['parentid', 'categoryid']].values:\n",
    "                parent_dict[parentid].add(categoryid)\n",
    "\n",
    "            union_dict = c_df.set_index('categoryid').to_dict()['parentid']\n",
    "\n",
    "            categoryid_siblings_dict = {}\n",
    "            for categoryid, parentid in union_dict.items():\n",
    "                if parentid in parent_dict:\n",
    "                    categoryid_siblings_dict[categoryid] = parent_dict[parentid] - set([categoryid])\n",
    "\n",
    "            cousins_dict = {}\n",
    "            for itemid, sibling_set in siblings_dict.items():\n",
    "                temp_set = set()\n",
    "                if common_dict[itemid] in categoryid_siblings_dict:\n",
    "                    for uncle in categoryid_siblings_dict[common_dict[itemid]]:\n",
    "                        temp_set.union(relatives_dict[uncle])\n",
    "                cousins_dict[itemid] = temp_set - sibling_set\n",
    "    \n",
    "    events = ['view', 'addtocart', 'transaction']\n",
    "    item_weights = {'view':item_view, 'addtocart':item_add, 'transaction':item_purchase}\n",
    "    relative_weights = {'view':relative_view, 'addtocart':relative_add, 'transaction':relative_purchase}\n",
    "    distant_relative_weights = {'view':relative_view, 'addtocart':relative_add, 'transaction':relative_purchase}\n",
    "    \n",
    "    for row, visitor in tqdm_notebook(enumerate(visitors), total = len(visitors)):\n",
    "        for col, product in enumerate(products):\n",
    "            for event in events:\n",
    "                if visitor in events_dict[event] and product in events_dict[event][visitor]:\n",
    "                    rank_matrix[row,col] += item_weights[event]\n",
    "                    if event in y_events:\n",
    "                        y_vals[row].add(product)\n",
    "                    if relative and product in siblings_dict:\n",
    "                        for sibling in siblings_dict[product]:\n",
    "                            rank_matrix[row, item_idx_dict[sibling]] += relative_weights[event]\n",
    "                    if distant_relative and product in cousins_dict:\n",
    "                        for cousin in cousins_dict[product]:\n",
    "                            rank_matrix[row, item_idx_dict[cousin]] += distant_relative_weights[event]\n",
    "        \n",
    "    return rank_matrix, np.fromiter(item_idx_dict.keys(), dtype=int), y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in the rank matrix, the numpy array of itemid's used to create the rank matrix\n",
    "the maximum number of predicted items you want returned for each row and a minimum threhold for rank value.\n",
    "The minimum threhold must be met for any item to be predicted. If it is not met an empty set is returned for that row\n",
    "regardless of the number of predicted items selected.\n",
    "'''\n",
    "def get_y_predict(rank_matrix, item_ids, num_top_vals=2, event_threshold=5):\n",
    "    index_array = np.argpartition(rank_matrix, num_top_vals)[:,-num_top_vals:]\n",
    "    y_predict = [set() for x in range(rank_matrix.shape[0])]\n",
    "    for row, indices in enumerate(index_array):\n",
    "        for idx in indices:\n",
    "            if rank_matrix[row,idx] > event_threshold:\n",
    "                y_predict[row].add(item_ids[idx])\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in the predicted items and compares them to the \n",
    "actual addtocart and or transaction items (depending on what was selected)\n",
    "it returns both a total hit rate ((correct_empty_predictions + correct_positive_predictions)/prediction_count)\n",
    "and a positive hit rate (correct_positive_predictions/number_of_times_ground_truth_was_not_empty)\n",
    "Note: a correct positive prediction occurs anytime the intersection between the predection set \n",
    "and groundtruth set is not empty thus correctly guessing one of the items in the ground truth set results\n",
    "in being counted as a correct prediction.\n",
    "'''\n",
    "def get_hit_rate(y_vals, y_predict):\n",
    "    hits = 0\n",
    "    both_empty = 0\n",
    "    y_not_empty = 0\n",
    "    for idx in range(len(y_predict)):\n",
    "        if (not y_vals[idx] and not y_predict[idx]):\n",
    "            both_empty += 1\n",
    "        elif y_vals[idx]:\n",
    "            y_not_empty += 1\n",
    "            if y_vals[idx].intersection(y_predict[idx]):\n",
    "                hits += 1\n",
    "    total_rate = (both_empty + hits)/len(y_predict)\n",
    "    positive_hit_rate = hits/y_not_empty\n",
    "    return total_rate, positive_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_matrix = get_rank_matrix(e_df=events_df.sample(n=int(.005*events_df.shape[0]), random_state=881))\n",
    "rank_matrix, itemids, y_vals = get_rank_matrix(e_df=get_reduced_events(), relative=True, distant_relative=True, relative_add=0, relative_purchase=0, item_add=0, item_purchase=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = get_y_predict(rank_matrix, itemids, num_top_vals=2, event_threshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy, hit_rate = get_hit_rate(y_vals, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_accuracy, hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recommender(rank_matrix, n_components = 20):\n",
    "    model = NMF(init='nndsvdar', verbose=1, n_components=20)\n",
    "    W = model.fit_transform(rank_matrix)\n",
    "    H = model.components_\n",
    "    return np.dot(W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(recommender, num_recs = 10):\n",
    "    y_predict = [set() for x in range(rank_matrix.shape[0])]\n",
    "    for index,row in tqdm_notebook(enumerate(recommender), total=len(recommender)):\n",
    "        sorted_row = sorted(row)\n",
    "        y_predict[index].update(set(sorted_row[-num_recs:]))\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = create_recommender(rank_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000027DCDEE5040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\std.py\", line 1124, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\notebook.py\", line 271, in close\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x0000027DCDEE5040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\std.py\", line 1124, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\notebook.py\", line 271, in close\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-e8df5a2f2441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-58ae85a2f5f5>\u001b[0m in \u001b[0;36mgenerate_recommendations\u001b[1;34m(recommender, num_recs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_recs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msorted_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnum_recs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         self.container = self.status_printer(\n\u001b[0m\u001b[0;32m    232\u001b[0m             self.fp, total, self.desc, self.ncols)\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# Prepare IPython progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "recs = generate_recommendations(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}